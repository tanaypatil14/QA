{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7489591,"sourceType":"datasetVersion","datasetId":4360508},{"sourceId":7549655,"sourceType":"datasetVersion","datasetId":4396953}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-08T17:27:44.750126Z","iopub.execute_input":"2024-02-08T17:27:44.750371Z","iopub.status.idle":"2024-02-08T17:27:45.100755Z","shell.execute_reply.started":"2024-02-08T17:27:44.750348Z","shell.execute_reply":"2024-02-08T17:27:45.099900Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/qa-main/val_data.csv\n/kaggle/input/qa-main/train_data.csv\n/kaggle/input/fin-qa-testing/Q_test_data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:28:27.607631Z","iopub.execute_input":"2024-02-08T17:28:27.608467Z","iopub.status.idle":"2024-02-08T17:28:27.612573Z","shell.execute_reply.started":"2024-02-08T17:28:27.608430Z","shell.execute_reply":"2024-02-08T17:28:27.611566Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_path ='/kaggle/input/qa-main/train_data.csv'\neval_path = '/kaggle/input/qa-main/val_data.csv'","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:28:30.439780Z","iopub.execute_input":"2024-02-08T17:28:30.440595Z","iopub.status.idle":"2024-02-08T17:28:30.444169Z","shell.execute_reply.started":"2024-02-08T17:28:30.440563Z","shell.execute_reply":"2024-02-08T17:28:30.443267Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(train_path)\neval_data = pd.read_csv(eval_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:28:31.998833Z","iopub.execute_input":"2024-02-08T17:28:31.999717Z","iopub.status.idle":"2024-02-08T17:28:32.043190Z","shell.execute_reply.started":"2024-02-08T17:28:31.999675Z","shell.execute_reply":"2024-02-08T17:28:32.042353Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_data.shape\neval_data.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:28:32.722178Z","iopub.execute_input":"2024-02-08T17:28:32.722504Z","iopub.status.idle":"2024-02-08T17:28:32.729356Z","shell.execute_reply.started":"2024-02-08T17:28:32.722477Z","shell.execute_reply":"2024-02-08T17:28:32.728288Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(96, 5)"},"metadata":{}}]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:28:33.481318Z","iopub.execute_input":"2024-02-08T17:28:33.481988Z","iopub.status.idle":"2024-02-08T17:28:33.499066Z","shell.execute_reply.started":"2024-02-08T17:28:33.481955Z","shell.execute_reply":"2024-02-08T17:28:33.498203Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                                  Q  \\\n0          36  how error minimization is done ? Is there any ...   \n1          49            Dealing with missing data in a dataset?   \n2         184  Which performance metric is better R2 or adjus...   \n3          53  What part of BERT's architecture gives it Bidi...   \n4         291  Suppose, if I have in channels= 3 and out chan...   \n\n                                                   A  \\\n0  Error minimization in machine learning involve...   \n1  Imputation methods, like mean or median imputa...   \n2  Adjusted R2 because the performance of predict...   \n3  The Transformer Encoder, which is a Bidirectio...   \n4  Yes, that's correct. In the context of a convo...   \n\n                                                  MQ  \\\n0  Elaborate on error minimization techniques in ...   \n1  How can missing values in a dataset be address...   \n2   Compared to R2, why is adjusted R2 a better p...   \n3  Which component of BERT's architecture provide...   \n4  I have in channels = 3 and out channels = 16, ...   \n\n                                                  MA  \n0  In machine learning error minimization, techni...  \n1  Imputation, deletion, ignoring (depending on t...  \n2   Adjusted R2 is more reliable since it conside...  \n3  Masked language model and next sentence predic...  \n4  In a Convolutional Neural Network (CNN), the i...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Q</th>\n      <th>A</th>\n      <th>MQ</th>\n      <th>MA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>36</td>\n      <td>how error minimization is done ? Is there any ...</td>\n      <td>Error minimization in machine learning involve...</td>\n      <td>Elaborate on error minimization techniques in ...</td>\n      <td>In machine learning error minimization, techni...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49</td>\n      <td>Dealing with missing data in a dataset?</td>\n      <td>Imputation methods, like mean or median imputa...</td>\n      <td>How can missing values in a dataset be address...</td>\n      <td>Imputation, deletion, ignoring (depending on t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>184</td>\n      <td>Which performance metric is better R2 or adjus...</td>\n      <td>Adjusted R2 because the performance of predict...</td>\n      <td>Compared to R2, why is adjusted R2 a better p...</td>\n      <td>Adjusted R2 is more reliable since it conside...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>53</td>\n      <td>What part of BERT's architecture gives it Bidi...</td>\n      <td>The Transformer Encoder, which is a Bidirectio...</td>\n      <td>Which component of BERT's architecture provide...</td>\n      <td>Masked language model and next sentence predic...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>291</td>\n      <td>Suppose, if I have in channels= 3 and out chan...</td>\n      <td>Yes, that's correct. In the context of a convo...</td>\n      <td>I have in channels = 3 and out channels = 16, ...</td>\n      <td>In a Convolutional Neural Network (CNN), the i...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"eval_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:28:34.099044Z","iopub.execute_input":"2024-02-08T17:28:34.100096Z","iopub.status.idle":"2024-02-08T17:28:34.110289Z","shell.execute_reply.started":"2024-02-08T17:28:34.100048Z","shell.execute_reply":"2024-02-08T17:28:34.109430Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                                  Q  \\\n0         106  What is the concept of \"function approximation...   \n1          53             Role of ML in artificial intelligence?   \n2         185                     What do you mean by AUC curve?   \n3          58  Is it The activation function output of the ne...   \n4          63  When our test accuracy is lesser than train ac...   \n\n                                                   A  \\\n0  Function approximation in Reinforcement Learni...   \n1  ML is a subset of AI; it empowers AI systems t...   \n2  AUC (area under curve). Higher the area under ...   \n3  The activation function output of a neuron is ...   \n4  Yes, a lower test accuracy compared to train a...   \n\n                                                  MQ  \\\n0  Reinforcement Learning: Explain the idea of us...   \n1  How does Machine Learning contribute to the br...   \n2                      Describe AUC curve in detail.   \n3  Confirm if the activation function outputs the...   \n4  Connect overfitting with lower test accuracy a...   \n\n                                                  MA  \n0  Function approximation in Reinforcement Learni...  \n1  ML is a subfield of AI focused on learning fro...  \n2  Area Under Curve (AUC) refers to the measure o...  \n3  Activation function output results from applyi...  \n4  Yes, when test accuracy is lower than train ac...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Q</th>\n      <th>A</th>\n      <th>MQ</th>\n      <th>MA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>106</td>\n      <td>What is the concept of \"function approximation...</td>\n      <td>Function approximation in Reinforcement Learni...</td>\n      <td>Reinforcement Learning: Explain the idea of us...</td>\n      <td>Function approximation in Reinforcement Learni...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53</td>\n      <td>Role of ML in artificial intelligence?</td>\n      <td>ML is a subset of AI; it empowers AI systems t...</td>\n      <td>How does Machine Learning contribute to the br...</td>\n      <td>ML is a subfield of AI focused on learning fro...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>185</td>\n      <td>What do you mean by AUC curve?</td>\n      <td>AUC (area under curve). Higher the area under ...</td>\n      <td>Describe AUC curve in detail.</td>\n      <td>Area Under Curve (AUC) refers to the measure o...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>58</td>\n      <td>Is it The activation function output of the ne...</td>\n      <td>The activation function output of a neuron is ...</td>\n      <td>Confirm if the activation function outputs the...</td>\n      <td>Activation function output results from applyi...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>63</td>\n      <td>When our test accuracy is lesser than train ac...</td>\n      <td>Yes, a lower test accuracy compared to train a...</td>\n      <td>Connect overfitting with lower test accuracy a...</td>\n      <td>Yes, when test accuracy is lower than train ac...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# data.columns","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:28:34.817283Z","iopub.execute_input":"2024-02-08T17:28:34.817932Z","iopub.status.idle":"2024-02-08T17:28:34.821543Z","shell.execute_reply.started":"2024-02-08T17:28:34.817892Z","shell.execute_reply":"2024-02-08T17:28:34.820591Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# train_data=data.sample(frac=0.8,random_state=42)\n# eval_data=data.drop(train_data.index)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:28:35.462295Z","iopub.execute_input":"2024-02-08T17:28:35.462877Z","iopub.status.idle":"2024-02-08T17:28:35.466418Z","shell.execute_reply.started":"2024-02-08T17:28:35.462825Z","shell.execute_reply":"2024-02-08T17:28:35.465502Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# !rm -rf /kaggle/working/QA_Train.txt","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:28:35.935300Z","iopub.execute_input":"2024-02-08T17:28:35.936074Z","iopub.status.idle":"2024-02-08T17:28:35.939837Z","shell.execute_reply.started":"2024-02-08T17:28:35.936039Z","shell.execute_reply":"2024-02-08T17:28:35.938898Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_data = train_data.drop('Unnamed: 0', axis=1)\neval_data = eval_data.drop('Unnamed: 0', axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:28:36.888196Z","iopub.execute_input":"2024-02-08T17:28:36.888989Z","iopub.status.idle":"2024-02-08T17:28:36.901214Z","shell.execute_reply.started":"2024-02-08T17:28:36.888952Z","shell.execute_reply":"2024-02-08T17:28:36.900254Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/working/QA_Test.txt', 'w') as file:\n    for index, row in eval_data.iterrows():\n        file.write(\"Question1 : \" + f\"{row['Q']}\" + \" Answer1 : \" + f\"{row['A']}\" + \"Question2 : \" + f\"{row['MQ']}\" + \"Answer2 : \" + f\"{row['MA']}\\n\")\nfile.close()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:28:37.518050Z","iopub.execute_input":"2024-02-08T17:28:37.518690Z","iopub.status.idle":"2024-02-08T17:28:37.531712Z","shell.execute_reply.started":"2024-02-08T17:28:37.518659Z","shell.execute_reply":"2024-02-08T17:28:37.530916Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/working/QA_Train.txt', 'w') as file:\n    for index, row in train_data.iterrows():\n        file.write(\"Question1 : \" + f\"{row['Q']}\" + \" Answer1 : \" + f\"{row['A']}\" + \"Question2 : \" + f\"{row['MQ']}\" + \"Answer2 : \" + f\"{row['MA']}\\n\")\nfile.close()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:28:38.778495Z","iopub.execute_input":"2024-02-08T17:28:38.779238Z","iopub.status.idle":"2024-02-08T17:28:38.849040Z","shell.execute_reply.started":"2024-02-08T17:28:38.779207Z","shell.execute_reply":"2024-02-08T17:28:38.848367Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"!pip uninstall -y transformers accelerate evaluate rouge_score\n!pip install transformers accelerate evaluate rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:28:40.307593Z","iopub.execute_input":"2024-02-08T17:28:40.308043Z","iopub.status.idle":"2024-02-08T17:29:07.516995Z","shell.execute_reply.started":"2024-02-08T17:28:40.308009Z","shell.execute_reply":"2024-02-08T17:29:07.515823Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Found existing installation: transformers 4.36.0\nUninstalling transformers-4.36.0:\n  Successfully uninstalled transformers-4.36.0\nFound existing installation: accelerate 0.25.0\nUninstalling accelerate-0.25.0:\n  Successfully uninstalled accelerate-0.25.0\n\u001b[33mWARNING: Skipping evaluate as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping rouge_score as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mCollecting transformers\n  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/85/f6/c5065913119c41ecad148c34e3a861f719e16b89a522287213698da911fc/transformers-4.37.2-py3-none-any.whl.metadata\n  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n\u001b[2K     \u001b[90m\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting accelerate\n  Obtaining dependency information for accelerate from https://files.pythonhosted.org/packages/a6/b9/44623bdb05595481107153182e7f4b9f2ef9d3b674938ad13842054dcbd8/accelerate-0.26.1-py3-none-any.whl.metadata\n  Downloading accelerate-0.26.1-py3-none-any.whl.metadata (18 kB)\nCollecting evaluate\n  Obtaining dependency information for evaluate from https://files.pythonhosted.org/packages/70/63/7644a1eb7b0297e585a6adec98ed9e575309bb973c33b394dae66bc35c69/evaluate-0.4.1-py3-none-any.whl.metadata\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.0)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.12.2)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24932 sha256=644bf20005f2516e77b235e73f106d315442f0c3a3d70528787fe6249d8d0998\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score, accelerate, transformers, evaluate\nSuccessfully installed accelerate-0.26.1 evaluate-0.4.1 rouge_score-0.1.2 transformers-4.37.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import LineByLineTextDataset\nfrom transformers import DataCollatorForLanguageModeling\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel\nfrom transformers import Trainer, TrainingArguments\n","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:29:07.518881Z","iopub.execute_input":"2024-02-08T17:29:07.519203Z","iopub.status.idle":"2024-02-08T17:29:23.126505Z","shell.execute_reply.started":"2024-02-08T17:29:07.519172Z","shell.execute_reply":"2024-02-08T17:29:23.125744Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install --upgrade tensorflow","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:29:23.127581Z","iopub.execute_input":"2024-02-08T17:29:23.128087Z","iopub.status.idle":"2024-02-08T17:30:20.288817Z","shell.execute_reply.started":"2024-02-08T17:29:23.128062Z","shell.execute_reply":"2024-02-08T17:30:20.287724Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.13.0)\nCollecting tensorflow\n  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/e3/ba/aa8a76eff5c20761b0361a5b4c9fccb8742c29a82adba7a8ad8ae819984e/tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.9.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nCollecting ml-dtypes~=0.2.0 (from tensorflow)\n  Obtaining dependency information for ml-dtypes~=0.2.0 from https://files.pythonhosted.org/packages/d1/1d/d5cf76e5e40f69dbd273036e3172ae4a614577cb141673427b80cac948df/ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.24.3)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (68.1.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.3.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.5.0)\nCollecting wrapt<1.15,>=1.11.0 (from tensorflow)\n  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n\u001b[2K     \u001b[90m\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.34.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.51.1)\nCollecting tensorboard<2.16,>=2.15 (from tensorflow)\n  Obtaining dependency information for tensorboard<2.16,>=2.15 from https://files.pythonhosted.org/packages/6e/0c/1059a6682cf2cc1fcc0d5327837b5672fe4f5574255fa5430d0a8ceb75e9/tensorboard-2.15.1-py3-none-any.whl.metadata\n  Downloading tensorboard-2.15.1-py3-none-any.whl.metadata (1.7 kB)\nCollecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow)\n  Obtaining dependency information for tensorflow-estimator<2.16,>=2.15.0 from https://files.pythonhosted.org/packages/b6/c8/2f823c8958d5342eafc6dd3e922f0cc4fcf8c2e0460284cc462dae3b60a0/tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata\n  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\nCollecting keras<2.16,>=2.15.0 (from tensorflow)\n  Obtaining dependency information for keras<2.16,>=2.15.0 from https://files.pythonhosted.org/packages/fc/a7/0d4490de967a67f68a538cc9cdb259bff971c4b5787f7765dc7c8f118f71/keras-2.15.0-py3-none-any.whl.metadata\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.22.0)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.4.4)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.0.9)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (1.26.15)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\nDownloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, ml-dtypes, keras, tensorboard, tensorflow\n  Attempting uninstall: wrapt\n    Found existing installation: wrapt 1.15.0\n    Uninstalling wrapt-1.15.0:\n      Successfully uninstalled wrapt-1.15.0\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.13.0\n    Uninstalling tensorflow-estimator-2.13.0:\n      Successfully uninstalled tensorflow-estimator-2.13.0\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml-dtypes 0.3.1\n    Uninstalling ml-dtypes-0.3.1:\n      Successfully uninstalled ml-dtypes-0.3.1\n  Attempting uninstall: keras\n    Found existing installation: keras 2.13.1\n    Uninstalling keras-2.13.1:\n      Successfully uninstalled keras-2.13.1\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.13.0\n    Uninstalling tensorboard-2.13.0:\n      Successfully uninstalled tensorboard-2.13.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.13.0\n    Uninstalling tensorflow-2.13.0:\n      Successfully uninstalled tensorflow-2.13.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.4 which is incompatible.\ntensorflow-decision-forests 1.5.0 requires tensorflow~=2.13.0, but you have tensorflow 2.15.0.post1 which is incompatible.\ntensorflow-text 2.13.0 requires tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.15.0.post1 which is incompatible.\ntensorflowjs 4.14.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\ntensorstore 0.1.51 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.2.0 tensorboard-2.15.1 tensorflow-2.15.0.post1 tensorflow-estimator-2.15.0 wrapt-1.14.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install sacrebleu","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:30:20.291147Z","iopub.execute_input":"2024-02-08T17:30:20.291460Z","iopub.status.idle":"2024-02-08T17:30:35.529300Z","shell.execute_reply.started":"2024-02-08T17:30:20.291430Z","shell.execute_reply":"2024-02-08T17:30:35.528116Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Collecting sacrebleu\n  Obtaining dependency information for sacrebleu from https://files.pythonhosted.org/packages/de/ea/025db0a39337b63d4728a900d262c39c3029b0fe76a9876ce6297b1aa6a0/sacrebleu-2.4.0-py3-none-any.whl.metadata\n  Downloading sacrebleu-2.4.0-py3-none-any.whl.metadata (57 kB)\n\u001b[2K     \u001b[90m\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m154.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Obtaining dependency information for portalocker from https://files.pythonhosted.org/packages/17/9e/87671efcca80ba6203811540ed1f9c0462c1609d2281d7b7f53cef05da3d/portalocker-2.8.2-py3-none-any.whl.metadata\n  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2023.8.8)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.24.3)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (4.9.3)\nDownloading sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m664.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-2.8.2 sacrebleu-2.4.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\nsacrebleu_metric = evaluate.load(\"sacrebleu\")\nrouge_metric = evaluate.load('rouge')","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:30:35.530757Z","iopub.execute_input":"2024-02-08T17:30:35.531075Z","iopub.status.idle":"2024-02-08T17:30:39.285153Z","shell.execute_reply.started":"2024-02-08T17:30:35.531045Z","shell.execute_reply":"2024-02-08T17:30:39.284238Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bffd13f123be4d5aace7c42d47b2a5d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2df4ab338efd455e9a30461a56b4add8"}},"metadata":{}}]},{"cell_type":"code","source":"# File paths\n\ntrain_path = \"/kaggle/working/QA_Train.txt\"\ntest_path = \"/kaggle/working/QA_Test.txt\"\noutput_dir = '/kaggle/working/output/'","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:30:39.286307Z","iopub.execute_input":"2024-02-08T17:30:39.286824Z","iopub.status.idle":"2024-02-08T17:30:39.291910Z","shell.execute_reply.started":"2024-02-08T17:30:39.286797Z","shell.execute_reply":"2024-02-08T17:30:39.290891Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# !rm -rf /kaggle/working/wandb\n","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:30:39.293525Z","iopub.execute_input":"2024-02-08T17:30:39.294428Z","iopub.status.idle":"2024-02-08T17:30:39.306833Z","shell.execute_reply.started":"2024-02-08T17:30:39.294349Z","shell.execute_reply":"2024-02-08T17:30:39.306079Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model_name = 'gpt2'\noverwrite_output_dir = False\nper_device_train_batch_size = 1\nnum_train_epochs = 12\nsave_steps = 1000","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:30:39.308058Z","iopub.execute_input":"2024-02-08T17:30:39.308393Z","iopub.status.idle":"2024-02-08T17:30:39.318133Z","shell.execute_reply.started":"2024-02-08T17:30:39.308360Z","shell.execute_reply":"2024-02-08T17:30:39.317247Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def load_data_collator(tokenizer, mlm = False):\n    data_collator = DataCollatorForLanguageModeling(\n        tokenizer=tokenizer,\n        mlm=mlm\n    )\n    return data_collator","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:30:39.319235Z","iopub.execute_input":"2024-02-08T17:30:39.321085Z","iopub.status.idle":"2024-02-08T17:30:39.328517Z","shell.execute_reply.started":"2024-02-08T17:30:39.321059Z","shell.execute_reply":"2024-02-08T17:30:39.327681Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n    return preds, labels\n\ndef preprocess_logits_for_metrics(logits, labels):\n    pred_ids = torch.argmax(logits, dim=-1)\n    return pred_ids, labels","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:30:39.331235Z","iopub.execute_input":"2024-02-08T17:30:39.331504Z","iopub.status.idle":"2024-02-08T17:30:39.339804Z","shell.execute_reply.started":"2024-02-08T17:30:39.331481Z","shell.execute_reply":"2024-02-08T17:30:39.339042Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(eval_preds):\n    logits, labels = eval_preds\n\n    # print(type(logits))\n    # print(len(logits))\n    # print('logits[0].shape:', logits[0].shape)\n    # print('logits[0]:', logits[0])\n    # print('logits[1].shape:', logits[1].shape)\n    # print('logits[1]:', logits[1])\n    # print('labels.shape:', labels.shape)\n    # print('labels:', labels)\n\n    preds = logits[0]\n    preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    preds, labels = postprocess_text(decoded_preds, decoded_labels)\n\n    # print(len(preds), len(labels))\n    # print(preds[0])\n    # print(labels[0])\n\n    result = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels)\n    blue_result = sacrebleu_metric.compute(predictions=decoded_preds, references=decoded_labels,lowercase = True)\n\n    # print(result)\n\n    return {\n        \"R1\": round(result[\"rouge1\"], 4),\n        \"R2\": round(result[\"rouge2\"], 4),\n        \"RL\": round(result[\"rougeL\"], 4),\n        \"RLsum\": round(result[\"rougeLsum\"], 4),\n        \"bleu\": round(blue_result[\"score\"], 4)\n    }","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:30:39.340972Z","iopub.execute_input":"2024-02-08T17:30:39.341239Z","iopub.status.idle":"2024-02-08T17:30:39.350881Z","shell.execute_reply.started":"2024-02-08T17:30:39.341215Z","shell.execute_reply":"2024-02-08T17:30:39.349984Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})\n\nmodel = GPT2LMHeadModel.from_pretrained(model_name)\nmodel.resize_token_embeddings(len(tokenizer))\nmodel.save_pretrained(output_dir)\n\ndef load_dataset(file_path, tokenizer):\n    dataset = LineByLineTextDataset(\n                tokenizer=tokenizer,\n                file_path=file_path,\n                block_size=512\n    )\n\n    return dataset\n\ntrain_dataset = load_dataset(train_path, tokenizer)\ntest_dataset = load_dataset(test_path, tokenizer)\n\n\ndata_collator = load_data_collator(tokenizer)\n\ntokenizer.save_pretrained(output_dir)\n\ntraining_args = TrainingArguments(\n          output_dir=output_dir,\n          evaluation_strategy = \"steps\",\n          eval_steps = 1000,\n          learning_rate=1e-5,\n          save_strategy = \"epoch\",\n          overwrite_output_dir=overwrite_output_dir,\n          per_device_train_batch_size=per_device_train_batch_size,\n          per_device_eval_batch_size=1,\n          num_train_epochs=num_train_epochs\n      )\n\ntrainer = Trainer(\n          model=model,\n          args=training_args,\n          data_collator=data_collator,\n          train_dataset=train_dataset,\n          eval_dataset=test_dataset,\n          preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n          compute_metrics=compute_metrics\n)\n\ntrainer.train()\ntrainer.save_model()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:30:39.352066Z","iopub.execute_input":"2024-02-08T17:30:39.352341Z","iopub.status.idle":"2024-02-08T17:46:01.815776Z","shell.execute_reply.started":"2024-02-08T17:30:39.352318Z","shell.execute_reply":"2024-02-08T17:46:01.814738Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33392f40fa194b7781408779aa181569"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25e4439db55a486ba3c327371f04caca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b649d1942c244b3b863d3c0bd6a2488"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ed10c74832b43c5914be7b626fc19c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e79fde66de23495980b54369ceb6ff62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89c9e85ac243409fac1ba385f1c6275f"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:119: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the  Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240208_173115-rg4iawgf</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tanaypatil691/huggingface/runs/rg4iawgf' target=\"_blank\">expert-gorge-28</a></strong> to <a href='https://wandb.ai/tanaypatil691/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tanaypatil691/huggingface' target=\"_blank\">https://wandb.ai/tanaypatil691/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tanaypatil691/huggingface/runs/rg4iawgf' target=\"_blank\">https://wandb.ai/tanaypatil691/huggingface/runs/rg4iawgf</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='13236' max='13236' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [13236/13236 14:13, Epoch 12/12]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>R1</th>\n      <th>R2</th>\n      <th>Rl</th>\n      <th>Rlsum</th>\n      <th>Bleu</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1000</td>\n      <td>2.997400</td>\n      <td>3.197643</td>\n      <td>0.474700</td>\n      <td>0.199200</td>\n      <td>0.368900</td>\n      <td>0.370500</td>\n      <td>24.515500</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>2.728800</td>\n      <td>3.054548</td>\n      <td>0.480900</td>\n      <td>0.201500</td>\n      <td>0.376800</td>\n      <td>0.378000</td>\n      <td>24.915700</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>2.471000</td>\n      <td>3.029690</td>\n      <td>0.482800</td>\n      <td>0.207500</td>\n      <td>0.383100</td>\n      <td>0.384400</td>\n      <td>25.501600</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>2.322900</td>\n      <td>2.997269</td>\n      <td>0.483200</td>\n      <td>0.207900</td>\n      <td>0.384400</td>\n      <td>0.385400</td>\n      <td>25.528000</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>2.239000</td>\n      <td>2.987695</td>\n      <td>0.487200</td>\n      <td>0.208300</td>\n      <td>0.385700</td>\n      <td>0.386800</td>\n      <td>25.705800</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>2.086100</td>\n      <td>2.993351</td>\n      <td>0.487100</td>\n      <td>0.207500</td>\n      <td>0.384300</td>\n      <td>0.386000</td>\n      <td>25.660000</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>2.038700</td>\n      <td>3.007855</td>\n      <td>0.485700</td>\n      <td>0.208300</td>\n      <td>0.386800</td>\n      <td>0.387900</td>\n      <td>25.710100</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>1.981800</td>\n      <td>3.027161</td>\n      <td>0.482200</td>\n      <td>0.207300</td>\n      <td>0.385200</td>\n      <td>0.386200</td>\n      <td>25.740700</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>1.977100</td>\n      <td>3.035964</td>\n      <td>0.481700</td>\n      <td>0.205500</td>\n      <td>0.382400</td>\n      <td>0.383900</td>\n      <td>25.450300</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>1.917600</td>\n      <td>3.037876</td>\n      <td>0.483800</td>\n      <td>0.207800</td>\n      <td>0.385700</td>\n      <td>0.387100</td>\n      <td>25.753800</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>1.886900</td>\n      <td>3.044813</td>\n      <td>0.481900</td>\n      <td>0.205800</td>\n      <td>0.382700</td>\n      <td>0.384300</td>\n      <td>25.540400</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>1.819900</td>\n      <td>3.053985</td>\n      <td>0.482500</td>\n      <td>0.206100</td>\n      <td>0.382900</td>\n      <td>0.384800</td>\n      <td>25.648600</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>1.879700</td>\n      <td>3.056191</td>\n      <td>0.482800</td>\n      <td>0.206700</td>\n      <td>0.383900</td>\n      <td>0.385500</td>\n      <td>25.748800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import GPT2LMHeadModel, GPT2Tokenizer\n\ndef load_gpt2_model(model_path):\n    tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n\n    model = GPT2LMHeadModel.from_pretrained(model_path)\n\n    return model, tokenizer\n\n# Replace 'path/to/your/gpt2/model' with the actual path where your GPT-2 model is saved\nmodel_path = '/kaggle/working/output'\ngpt2_model, gpt2_tokenizer = load_gpt2_model(model_path)\n\n\n\n\ndef generate_output_gpt2(model, tokenizer, question, temperature=1.0, top_p=0.9, max_length=50):\n    # Tokenize the input question\n    input_ids = tokenizer.encode(question, return_tensors=\"pt\")\n\n    # Generate the model output with temperature and top-p sampling\n    model_output = model.generate(\n        input_ids,\n        max_length=max_length,\n        pad_token_id=tokenizer.eos_token_id,\n        temperature=temperature,\n        top_p=top_p,\n        top_k=50,\n    )\n\n    # Decode the generated output\n    generated_output = tokenizer.decode(model_output[0], skip_special_tokens=True)\n\n    return generated_output\n\n# Example question with temperature=0.7 and top-p=0.9\ninput_question = \"What NLP?\"\n\n# Get the generated output\noutput = generate_output_gpt2(gpt2_model, gpt2_tokenizer, input_question, temperature=0.7, top_p=0.9)\n\n# Print or use the generated output\nprint(output)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:46:01.817348Z","iopub.execute_input":"2024-02-08T17:46:01.817793Z","iopub.status.idle":"2024-02-08T17:46:04.147005Z","shell.execute_reply.started":"2024-02-08T17:46:01.817755Z","shell.execute_reply":"2024-02-08T17:46:04.145935Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"What NLP?  It's a subset of machine learning, where the goal is to learn from data and apply it to new problems.  It's a subset of machine learning that focuses on problem-solving and problem-solving without the\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_model(model_path):\n    model = GPT2LMHeadModel.from_pretrained(model_path)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:50:50.196886Z","iopub.execute_input":"2024-02-08T17:50:50.197775Z","iopub.status.idle":"2024-02-08T17:50:50.205612Z","shell.execute_reply.started":"2024-02-08T17:50:50.197740Z","shell.execute_reply":"2024-02-08T17:50:50.204598Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def load_tokenizer(tokenizer_path):\n    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n    return tokenizer\n","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:50:50.906682Z","iopub.execute_input":"2024-02-08T17:50:50.907310Z","iopub.status.idle":"2024-02-08T17:50:50.912746Z","shell.execute_reply.started":"2024-02-08T17:50:50.907275Z","shell.execute_reply":"2024-02-08T17:50:50.911877Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def generate_text(sequence, max_new_tokens):\n    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n    input_length = ids.size(1)\n    max_length = input_length + max_new_tokens\n    final_outputs = model.generate(\n        ids,\n        do_sample=True,\n        max_length=max_length,\n        pad_token_id=model.config.eos_token_id\n    )\n    return tokenizer.decode(final_outputs[0], skip_special_tokens=True)\n\n\n\n\nmodel_path = '/kaggle/working/output'\nmodel = load_model(model_path)\ntokenizer = load_tokenizer(model_path)\n\n\ndef root(prompt: str):\n    result = generate_text(\"Question: \" + prompt + \"Answer: \", 35).split('Answer: ')[1]\n    try:\n        result = result.split('.')[0] + '.'\n    except Exception as e:\n        print(e)\n    return result\n\nroot('what is K-mean algorithm?')","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:03:50.047512Z","iopub.execute_input":"2024-02-04T05:03:50.047906Z","iopub.status.idle":"2024-02-04T05:03:51.873197Z","shell.execute_reply.started":"2024-02-04T05:03:50.047876Z","shell.execute_reply":"2024-02-04T05:03:51.872067Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"' In K-Means,  the k-mean component is the median value (in terms of importance) of the predicted value in the class.'"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n\n# def load_model(model_path):\n#     model = GPT2LMHeadModel.from_pretrained(model_path)\n#     return model\n\n# def load_tokenizer(tokenizer_path):\n#     tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n#     return tokenizer\n\ndef generate_text(sequence, max_new_tokens):\n    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n    input_length = ids.size(1)\n    max_length = input_length + max_new_tokens\n    final_outputs = model.generate(\n        ids,\n        do_sample=True,\n        max_length=max_length,\n        pad_token_id=model.config.eos_token_id\n    )\n    return tokenizer.decode(final_outputs[0], skip_special_tokens=True)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:51:00.818469Z","iopub.execute_input":"2024-02-08T17:51:00.819180Z","iopub.status.idle":"2024-02-08T17:51:00.825995Z","shell.execute_reply.started":"2024-02-08T17:51:00.819146Z","shell.execute_reply":"2024-02-08T17:51:00.824915Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(csv_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:30:01.304589Z","iopub.execute_input":"2024-02-04T05:30:01.305015Z","iopub.status.idle":"2024-02-04T05:30:01.314984Z","shell.execute_reply.started":"2024-02-04T05:30:01.304983Z","shell.execute_reply":"2024-02-04T05:30:01.313787Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:30:14.371751Z","iopub.execute_input":"2024-02-04T05:30:14.372189Z","iopub.status.idle":"2024-02-04T05:30:14.381376Z","shell.execute_reply.started":"2024-02-04T05:30:14.372155Z","shell.execute_reply":"2024-02-04T05:30:14.380369Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"Q    object\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"def generate_answers_from_csv(csv_path, max_new_tokens):\n    df = pd.read_csv(csv_path)\n    df['Q'] = df['Q'].astype(str)\n    generated_answers = []\n\n    for index, row in df.iterrows():\n        question = row['Q']  # Adjust column name as per your CSV\n        answer = generate_text(\"Question: \" + question + \"Answer: \", max_new_tokens).split('Answer: ')[1]\n\n        try:\n            answer = answer.split('.')[0] + '.'\n        except Exception as e:\n            print(e)\n\n        generated_answers.append({'Question': question, 'Answer': answer})\n\n    return generated_answers\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:51:06.423483Z","iopub.execute_input":"2024-02-08T17:51:06.423837Z","iopub.status.idle":"2024-02-08T17:51:06.432978Z","shell.execute_reply.started":"2024-02-08T17:51:06.423809Z","shell.execute_reply":"2024-02-08T17:51:06.431893Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '/kaggle/working/output'\nmodel = load_model(model_path)\ntokenizer = load_tokenizer(model_path)\n\ncsv_path = '/kaggle/input/fin-qa-testing/Q_test_data.csv'\nmax_new_tokens = 35\ngenerated_answers = generate_answers_from_csv(csv_path, max_new_tokens)\n\n\n\n# Create a DataFrame from the list of dictionaries\ndf_generated_answers = pd.DataFrame(generated_answers)\n\n# Save the DataFrame to a CSV file\noutput_csv_path = '/kaggle/working/generated_answers.csv'\ndf_generated_answers.to_csv(output_csv_path, index=False)\n\nprint(\"Generated answers saved to:\", output_csv_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:51:12.396008Z","iopub.execute_input":"2024-02-08T17:51:12.396635Z","iopub.status.idle":"2024-02-08T17:56:14.871614Z","shell.execute_reply.started":"2024-02-08T17:51:12.396599Z","shell.execute_reply":"2024-02-08T17:56:14.870662Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Generated answers saved to: /kaggle/working/generated_answers.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"for item in generated_answers:\n    print(f\"Question: {item['Question']}\\nAnswer: {item['Answer']}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-02-08T18:04:11.662060Z","iopub.execute_input":"2024-02-08T18:04:11.662827Z","iopub.status.idle":"2024-02-08T18:04:11.696547Z","shell.execute_reply.started":"2024-02-08T18:04:11.662794Z","shell.execute_reply":"2024-02-08T18:04:11.695527Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Question: Can an SVM use gradient descent to maximize its margin?\nAnswer:  Gradient descent has several advantages over traditional deep learning, including avoiding overfitting, maximizing accuracy.\n\nQuestion: How to deal with the curse of dimensionality?\nAnswer:  Dimensionality is a generalization problem, as it entails taking dimensions that are not consistent with the data dimensions.\n\nQuestion: Importance of bias-variance tradeoff in ML?\nAnswer:  Bias-variance is often associated with generalization error, but not generalization error.\n\nQuestion: What is the main contribution of the paper \"Tree-structured regional CNN-LSTM model for dimensional sentiment analysis\" by Wang et al.?\nAnswer:  This paper proposes unsupervised global neural networks designed to incorporate feature-driven model learning, enabling deep sentiment analysis.\n\nQuestion: Can KNN be used for regression tasks?\nAnswer:  Logistic Regression models include supervised learning (M), supervised learning (S), and regression-based kernels for classification tasks.\n\nQuestion: What are some commonly used algorithms available in Scikit-Learn?\nAnswer:  Some popular algorithms are Pandas, Starlette, XRM, KNN, RNN, GPTK, and BERT.\n\nQuestion: Both Picture & Text are Static, while Audio & Video are Dynamic, so we need to firstly convert to Static Picture Equivalent to apply CNN ?\nAnswer:  Both Picture & Text models exhibit dynamic relationships, facilitating sharing of sound data and creating engaging multimedia experiences.\n\nQuestion: What is the main difference between a GRU and an LSTM?\nAnswer:  A GRU consists of a linear kernel with a bounding box, leading to a self-attention mechanism.\n\nQuestion: what is the reason for making the sample again 100% by adding the replication ...instead of just using 67%\nAnswer:  Using the sample again, we add samples from diverse regions of a dataset and make changes to the model to improve the accuracy of the outcome (i.\n\nQuestion: How would you evaluate a logistic regression model?\nAnswer:  Logistic regression predicts only one-factors - errors.\n\nQuestion: What is the difference between Policy and Value function in Reinforcement Learning?\nAnswer:  Policy involves ensuring that the reward is positive when used as goals in the past, and value involves ensuring the reward is negative when used in the future.\n\nQuestion: Define the learning rate in Deep Learning.\nAnswer:  In deep learning, learning rate is the continuous learning rate (CEL), as long as the learning curve is relatively stable.\n\nQuestion: What are hard margin and soft margin SVMs?\nAnswer:  Soft margin refers to the percentage of the variance in a line segment that is not filled in by the input to the segment, and hard margin, a measure of the margin between.\n\nQuestion: Can a Linear Classifier handle non-linearly separable data?\nAnswer:  Linear Classifiers can handle non-linearly separable datasets, using Euclidean distance algorithms and dimensionality reduction.\n\nQuestion: is data normalization/scaling is applicable in speech recognition\nAnswer:  Data normalization or scaling is applied to reduce or eliminate noise and improve signal independence in speech recognition models.\n\nQuestion: What is the main purpose of a Denoising Autoencoder (DAE)?\nAnswer:  In a denoising autoencoder (DAE), a denoising autoencoder (DAE) retains the internal representations of the input sequence within a.\n\nQuestion: How does Feature Engineering impact Machine Learning (ML)?\nAnswer:  As with other machine learning topics, Feature Engineering can be an important tool for improving ML models by incorporating features and improving their reliability and relevance to complex problems within the domain of machine.\n\nQuestion: how do I get future predicted levels for not just 1 year or say next 10 future years\nAnswer:  You can use conditional independence to predict all future estimates using prediction intervals.\n\nQuestion: How are we connecting one hidden layer to another in the example shown?\nAnswer:  In the example shown, the hidden layers in the ensemble are the same ones in the original dataset, providing a stable understanding of the ensemble structure.\n\nQuestion: What is deep transfer learning (DTL)?\nAnswer:  Deep transfer learning (DTL) involves transforming a series of computations into new outputs, capturing and learning information without the need for individual neurons.\n\nQuestion: What are the types of features in CV\nAnswer:  CV features are regularization techniques used to improve feature extraction, mitigating bias and improving model performance.\n\nQuestion: Is an autoencoder ideally symmetric? Will slow compression over many layers and abrupt expansion over a few layers lead to data loss?\nAnswer:  An autoencoder may be preferred over compression over multiple layers for storage and robustness.\n\nQuestion: Determining the best algorithm for a dataset in ML?\nAnswer:  While there are a few different types of algorithms that can be chosen for a dataset, there are a wide range of algorithms that can be chosen.\n\nQuestion: Does SVM also needs scaling\nAnswer:  SVM can use any number of variables, creating its own internal scaling equation and applying it for a wide variety of cases, from classification tasks.\n\nQuestion: What is the advantage of using positional encoding in the Transformer architecture?\nAnswer:  It allows the receiver to generate sequence of positional data automatically based on the inputs of the original input sequence, enabling its multi-task handling by the context-sensitive input.\n\nQuestion: What is the key contribution of the paper \"Deep-Sentiment: Sentiment Analysis using Ensemble of CNN and Bi-LSTM Models\" by Minaee et al.?\nAnswer:  This crucial paper sets out to introduce the use of deep-sentiment-based sentiment analysis techniques in deep learning models, specifically for detecting patterns and addressing complex interactions in artificial neural.\n\nQuestion: What are Eigenvalues?\nAnswer:  Eigenvectors are sequences of numbers arranged in a circular pattern encompassing points, values, and positions.\n\nQuestion: Do we have tools to annotate if we are building our own training data set?\nAnswer:  Metrics like F1 Score, Sigmoid, Bias Score, etc.\n\nQuestion: what is DNN?\nAnswer:  DNN stands for Deep Neural Network (CNN), also known as an artificial neural network.\n\nQuestion: What is uvicorn? Why should it be used with FastAPI?\nAnswer:  uvapi has two main functions that handle GET, POST, and DELETE requests: GET and DELETE.\n\nQuestion: Can we say data mining is  kind of check(interpret and make sure what exactly we are going to do) before the machine takes any decision based on algorithms?\nAnswer:  Yes, data mining can be considered pre-trained, pre-imaged, and indeed, a lot of the pre-training processes have impact on the machine learning algorithms used.\n\nQuestion: Explain Batch Gradient Descent.\nAnswer:  Gradient Descent involves adjusting the number of steps before a new iteration to prevent its occurrence.\n\nQuestion: Does GloVe provide vectors for all words?\nAnswer:  GloVe provides vectors for all words in the English Language Analysis (LAGA), which helps develop robust models and enhance contextual understanding in semantic and analytical fields.\n\nQuestion: Whats the difference between a generative and discriminative model?\nAnswer:  A generative model has generative features; discriminative features are not.\n\nQuestion: Different types of optimizers used in neural networks?\nAnswer:  In neural networks, pruning techniques like normalization, pass filtering, and anomaly removal enable specific types of optimizers.\n\nQuestion: aren't we doing convolution to reduce the dimensionality?\nAnswer:  Convolutional Neural Networks, on the other hand, do not directly parallelize across epochs.\n\nQuestion: How does deep learning relate to other areas of computer science?\nAnswer:  Deep learning, also known as reinforcement learning, enhances supervised learning by enhancing the predictive power of model predictions.\n\nQuestion: How can both false positive and true positive approach 1? are they not mutually exclusive?\nAnswer:  In the present study, false positive approaches 1 and false negative approaches 2 are mutually exclusive, with false positives (ignoring outliers) being observed jointly.\n\nQuestion: What is the main advantage of using Multi-Layer Perceptron (MLP) over other deep learning architectures?\nAnswer:  Multi-Layer Perceptron (MLP) enhances model complexity while providing superior performance, efficiency, and versatility compared to other deep learning architectures.\n\nQuestion: which is better Word2Vec or GloVe?\nAnswer:  GloVe is more reliable than Word2Vec for text verification because it uses word embeddings instead of single words, which can be beneficial for text validation.\n\nQuestion: How does the Transformer model account for the order of the words in the input sequence?\nAnswer:  The model assumes that each word in the input sequence can occur one by one.\n\nQuestion: Explain Forward and Back Propagation in the context of deep learning.\nAnswer: 眉 is a term used to refer to the neural network's ability to learn and process information during processing using backward recursion, a process in the training network to reconstruct information without.\n\nQuestion: Does Unsupervised Learning always apply to grouping/clustering ? Or is there anything else they apply to?\nAnswer:  Unsupervised learning applies, but often in groups, clustering or grouping tasks involves individual neurons rather than individual neurons in a single neuron layer.\n\nQuestion: What is the main purpose of using attention mechanisms in deep learning frameworks?\nAnswer:  Attention mechanisms work as a method to focus attention on individual regions in the network (e.\n\nQuestion: Differentiate between Statistical Modeling and Machine Learning?\nAnswer:  Stochastic Gradient Descent (SGD): A statistical model is trained on the data (closest data points) at various intervals to perform well on smaller samples.\n\nQuestion: How does Deep Learning differ from Machine Learning\nAnswer:  Deep Learning uses hidden layers to learn patterns from data.\n\nQuestion: What is self-attention in a Transformer network, and how does it differ from other types of attention mechanisms?\nAnswer:  Self-attention in a Transformer network consists of observing and reacting to external inputs in response to their presence or absence.\n\nQuestion: Does gamma close to 0 lead to overfitting or 1 lead to overfitting?\nAnswer:  Gamma close to 0 prevents overfitting by averaging data, leading to overfitting.\n\nQuestion: could you please give the names of pre-trained other models here for sentiment analysis\nAnswer:  ML models are generally known for being effective in sentiment analysis, being able to learn contextual representations without explicitly addressing the underlying contextQuestion2 : Elaborate on the various types of.\n\nQuestion: What is NLP? What are the various components of NLP?\nAnswer:  NLP is a basic human-computer interaction model (hilto-action) model with a goal of improving the performance of human beings by providing tools for self-organ.\n\nQuestion: Deep learning is for only Classification problems?\nAnswer:  Deep learning is not for learning classification problems.\n\nQuestion: Name some techniques of overcoming challenges viz. Non-Convexity, Plateau, Vanishing and Exploding Gradients faced during the training of a deep neural network?\nAnswer:  To tackle non-convexity problems like vanishing gradients, vanishing gradients, vanishing gradients, exploding gradients, vanishing gradients, vanishing gradients, vanishing.\n\nQuestion: what should be ideal/Max value for N-gram, increase in N-gram value may lead to sparsity problem \nAnswer:  In N-gram, the ideal value of the maximum value to maximize Sparsity (maximize N-gram fragments) would be (max(maxmaximizes 1,.\n\nQuestion: Give some applications of Siamese networks\nAnswer:  Siamese networks can be used for text prediction, image recognition, and other tasks where input data is more direct and interpretable than input data.\n\nQuestion: What is API ?\nAnswer:  API is a set of APIs used in the web framework.\n\nQuestion: How does the Transformer architecture handle tasks that require modeling, both the sequence and the context, such as question answering?\nAnswer:  The Transformer architecture handles tasks like sequence processing, handling categorical forms (Question2 and Answer2), context awareness and task-specific representations in the context of Machine Learning operations.\n\nQuestion: What is Knowledge Distillation?\nAnswer:  Knowledge Distillation is a method of extracting meaningful information from known data points to create an accurate representation of the data.\n\nQuestion: What is MFCC?\nAnswer:  The term \"MLCC\" (ML-Catch Classification Interchange Error) is commonly used to refer to the rate-change rate at which the training data learns a sequence.\n\nQuestion: Whats the F1 score? How would you use it\nAnswer:  F1 is considered a popular test metric because it refers to the sum of factors that contribute to a test's performance.\n\nQuestion: It seems sklearn.SVM with linear still indentifies the support vectors for a circular data distribitution - then why cant it predict the decision boundary?\nAnswer:  There are two reasons why linear and circular data distribibels the decision boundary, one in terms of the map of features to the closest separable data boundary.\n\nQuestion: What is the main issue that LSTM networks solve?\nAnswer:  LSTM networks solve the problem of dealing with multiple input pairs, providing efficient multi-level representation for word embeddings.\n\nQuestion: Thoughts on fairness of ML algorithms debate?\nAnswer:  Fairness, independence, generative power, precision, generative error, reliability.\n\nQuestion: How does the Transformer model select the words to translate?\nAnswer:  The Transformer model honors both human and machine translation by selecting the words based on the context, using contextual cues to capture contextual information, and by refining its knowledge-processing.\n\nQuestion: Suppose, if I have in channels= 3 and out channels = 16, then does it means 16 times filter will move across Image matrix do generate features.\nAnswer:  No.\n\nQuestion: What is a Bidirectional LSTM?\nAnswer:  Bidirectional LSTM is a method which splits the input signal into independent sub-images whose values are set in the neural network's output layer.\n\nQuestion: What are the different layers in ANN? What is the notation for representing a node of a particular layer?\nAnswer:  The layer represented in the ANN structure is called a layer.\n\nQuestion: Can RGBa Images be considered as a 4D array?\nAnswer:  Yes, 4D arrays are considered as a 4D array by the BERT criteria.\n\nQuestion: What is the primary advantage of bidirectional context modeling in models like BERT?\nAnswer:  Unlike other deep learning models, BERT allows authors to focus on the most salient parts of their source sentence in separate contexts.\n\nQuestion: How does the bias-variance tradeoff relate to model overfitting?\nAnswer:  In the bias-variance tradeoff, model overfitting is associated with a better prediction in a model, while overfitting predicts imporients for model input.\n\nQuestion: Aren't we doing convolution to reduce dimensionality?\nAnswer:  Convolution techniques are widely employed for enhancing the performance of deep learning models, typically by increasing convolutional weights and improving the submitted pixel data's spatial resolution.\n\nQuestion: Please give an example of 4 dimensions.\nAnswer:  X1 : The dimension of 1 is the width of the square root of x.\n\nQuestion: What is the CART algorithm ?\nAnswer:  The CART algorithm is a pre-trained neural network with specific preprocessing provided by a trained model trained on the input data.\n\nQuestion: How do AI-ML avatars enhance user experiences?\nAnswer:  AI-ML avatars enhance user experiences by combining technology, contextual awareness, and collaborative knowledge to enhance user experience and enhance their autonomy.\n\nQuestion: How do we visualise these layers & filters? Do we simply treat weights as RGB pixel values? What if some numbers are beyond 0-255 range?\nAnswer:  One way of visualising these layers and filters involves treating weights as pixels or RGB values.\n\nQuestion: What is convex optimization?\nAnswer:  Convex optimization, often incorrectly referred to as convex propagation in machine learning, is a procedure in the optimization of a model's performance to eliminate the loss or unwanted features.\n\nQuestion: How would you define the number of clusters in a clustering algorithm?\nAnswer:   The number of clusters in a clustering algorithm is defined by multiplying the number of neighbors by the number of features in the entire dataset.\n\nQuestion: What are Exploding Gradients and Vanishing Gradients?\nAnswer:  Exploding Gradients are a measure of the gradients in the learning rate, typically decreasing as the training progresses.\n\nQuestion: What is Pragmatic Ambiguity in NLP? \n\nAnswer:  Pragmatizing takes care of the ambiguity between the meaning of a sentence and the context in which it is used.\n\nQuestion: What is the key property of the Transformer architecture that allows for parallel execution of different paths in the encoder?\nAnswer:  The key feature of the Transformer architecture allows for parallelization of the data in different stages of the output layer.\n\nQuestion: What is Q-Learning, and how does it work?\nAnswer:  Q-Learning is a supervised learning algorithm that trains neural networks in a supervised learning environment.\n\nQuestion: What is the main idea behind combining a sparse autoencoder with an SVM for network intrusion detection?\nAnswer:  The idea behind combining a sparse autoencoder with an SVM for network intrusion detection is to combine the performance of a sparse autoencoder with a hyperparameter.\n\nQuestion: Explain the Next Sentence Prediction (NSP) task.\nAnswer:  The Next Sentence Prediction (NSP) task involves the prediction of a sentence with respect to the sentence preceding it, through multiple iterations.\n\nQuestion: What is the main advantage of deep learning over traditional machine learning algorithms?\nAnswer:  Deep learning outperforms traditional machine learning algorithms by leveraging computational resources, efficiency, and predictive power on complex data sets.\n\nQuestion: What are some real-world application areas where deep learning techniques are being used?\nAnswer:  Deep learning techniques like deep learning techniques like discriminative linear regression, convolutional neural networks, and generative adversarial networks are common application areas for traditional machine learning approaches.\n\nQuestion: What is the output of the Image Decoder component in Stable Diffusion?\nAnswer:  In Stable Diffusion, the output of the Image Decoder is produced by multiplying the output of the Stable Diffusion matrix by the input of the image generation process.\n\nQuestion: What is the ultimate goal of developing a faster-unsupervised training technique for each sub-network in a DBN?\nAnswer:  FastUnsupervisedTraining provides a comprehensive set of techniques that can be utilized to analyze and learn from data in a DBN network, including convolutional, supervised, and.\n\nQuestion: can we apply Autoencoder on numerical dataset for dimensionality reduction\nAnswer:  Autoencoders (as well as linearization techniques such as gradient descent) can be applied to numerical datasets for dimensionality reduction, allowing for a non-linear approach to.\n\nQuestion: Is there a difference between underfitting and overfitting?\nAnswer:  Underfitting depends on the model; overfitting considers generalization of performance, while fit considers specific patterns.\n\nQuestion: How does K-Means clustering determine cluster centroids?\nAnswer:  Leads to increased likelihood of clustering clusters, as the number of clusters in a dataset grows.\n\nQuestion: can we have bigram, trigram or ngram implemented in a single sentence?\nAnswer:  No, bigram and trigram can handle complex sentences or words, which is fine if it's a regular word processing problem.\n\nQuestion: How to Tackle Overfitting and Underfitting?\nAnswer:  In data manipulation, it is often preferred to analyze and test data with multiple imputation methods before imputation during training or in training.\n\nQuestion: Deep learning vs. machine learning?\nAnswer:  Deep learning (DL) and machine learning (ML) differ in their preferred approaches for various tasks, impacting performance and efficiency in various tasks, including human and machine learning.\n\nQuestion: How does Filter work in Text? Because its no more numbers? Is text also considered as image and pixels are extracted?\nAnswer:  All textual input has a specific size and shape, and Filter takes those parameters into account to optimize its output.\n\nQuestion: What is the optimization method proposed in the paper \"An Optimization Method for Intrusion Detection Classification Model Based on Deep Belief Network\" by Wei et al.?\nAnswer:  The optimization method in the paper deals with handling errors and learning from them, effectively improving accuracy in imputation tasks.\n\nQuestion: Address the exploding gradient problem in backpropagation?\nAnswer:  Gradient Boosting involves boosting or minimizing one's gradient by performing a transformation to reduce one's dependence on the original variable, often called a residual.\n\nQuestion: What is regularization and how does it work?\nAnswer:  Regularization helps define and evaluate features in the data, guiding model selection, validation, decision making and performance.\n\nQuestion: What is the focus of the research paper \"A Combined Deep CNN-LSTM Network for the Detection of Novel Coronavirus (COVID-19) Using X-Ray Images\" by Islam et al.?\nAnswer:  The focus of the paper is the development of a combined deep CNN-LSTM network (CNN) for the detection of novel contaminating diseases and their target types by embed.\n\nQuestion: What is a Support Vector Machine (SVM) in Machine Learning?\nAnswer:  A Support Vector Machine (SVM) is a flexible machine learning model with limited capability for complex data structures.\n\nQuestion: So Noise is different from Outliers?\nAnswer:  Noise in a data set can be predicted using models trained on it, which include noise variables like color, proximity to noise, and size of the noise data, which can be.\n\nQuestion: is RNN doing backpropagation with the help of human?\nAnswer:  In RNN (ReLU), pruning occurs by using the backward propagation function to return some convolutional weights to the model, minimizing its original values.\n\nQuestion: What is an activation function? What is the use of an activation function?\nAnswer:  An activation function is a mathematical mathematical operation that assigns probabilities to the values of two independent variables.\n\nQuestion: In K-fold, since we have K models, while deploying, can we deploy all K models & take median/mode prediction for future data points?\nAnswer:  In K-fold, the primary task of K-fold deployment is to learn the optimal k-fold function.\n\nQuestion: Do we have tools to annotate if we are building our own training data set?\nAnswer:  No one toolologies are universally applicable to building model training datasets with very few trained samples.\n\nQuestion: What are the advantages of neural networks?\nAnswer:  Neural Networks have the advantage of being able to learn complex hierarchical hierarchical representations, unlike typical machine learning, orGANs, which have limited ability to learn complex hierarchical representations compared to.\n\nQuestion: Preventing overfitting in ML models?\nAnswer:  Overfitting is a class of problems that can happen randomly, affecting performance on tasks as diverse as image recognition and deep learning.\n\nQuestion: How does the decoding component in the Transformer model use the attention mechanism?\nAnswer:  The attention mechanism in the Transformer model uses a preprocessing vector to update the attention vector as the input to the Transformer, which takes an input sequence and outputs it as.\n\nQuestion: Does SVM also need scaling?\nAnswer:  Yes, SVM scales data in large enough batches to make it feasible for parallel algorithms to learn from input data, and it is possible to have parallel algorithms learn from both.\n\nQuestion: Suppose we have learned weights for 1 data row\nAnswer:  We can't compute weights for all observations of a row.\n\nQuestion: What is the main purpose of deep learning techniques in the field of artificial intelligence?\nAnswer:  Deep learning techniques leverage existing techniques and insights from deep learning models to improve intelligence, improve efficiency, and enhance quality of life.\n\nQuestion: How can we generate the representations from established/pretrained models for use of them in our classifiers? Do we have a process/pipeline we leverage?\nAnswer:  Training platforms like Machine Learning (ML), PyTorch (PyTorch is a hyperparameter tuning tool), and Machine Learning models like PyTorch have been widely adopted.\n\nQuestion: How would you make a sentiment classifier? \n\nAnswer:  A sentiment classifier is a deep learning (ML) classifier that can recognize hidden patterns in data, allowing it to distinguish similarities and differences between different categories.\n\nQuestion: How does Regularization apply to Linear Regression models?\nAnswer:  In Linear Regression, regularization is applied to both continuous and categorical variables, affecting both prediction and prediction accuracy.\n\nQuestion: Is it possible to train a neural network model by setting all biases to 0? Also, is it possible to train a neural network model by setting all of the weights to 0?\nAnswer:  To create a neural network model using all biases set in  the  training data, a bias reduction is added to the training data to remove as much of the data as possible.\n\nQuestion: Does ReLU help with non-linearity?\nAnswer:  Yes, ReLU measures non-linearity and independence, and it does this by dividing the input by the output to account for changes in the data.\n\nQuestion: does the same hypothesis apply even when its unsupervised learning since there is no Y ?\nAnswer:  Supervised learning applies even when it assumes regularizna with n exceptions like when it assumes the y-axes have no standard deviation on them.\n\nQuestion: Can we associate a particular kernel with a particular problem statement or domain?\nAnswer:  NumPy can assign kernel to specific problems, aiding handling complex problems.\n\nQuestion: how to webscrap pages with password?\nAnswer:  To scrape or extract passwords from webpages, one has to be a user, or password.\n\nQuestion: If we dont have the raw data, but only the bar charts or say line graphs, can we read those and form our data ?\nAnswer:  Yes, you can read and interpret text data, but only with the raw data.\n\nQuestion: What is the purpose of the \"dropout\" technique used in CNNs?\nAnswer:  In CNNs, \"dropout\" refers to using a feature extraction algorithm to remove a random input from several independent layers of Breeze state machines.\n\nQuestion: What is a Masked Language Model? \n\nAnswer:  A Masked Language Model is a system-level representation of a sentence, often called a syntactic structure, that incorporates other words, forming a unified sentence.\n\nQuestion: Identifying and dealing with outliers in data?\nAnswer:  Univariate data are rare, but they form important components of regression models, especially for feature extraction.\n\nQuestion: Could you please talk about number of nodes in each hidden layer?\nAnswer:  In neural networks, there are a few types of nodes, which belong to each subnet of the hidden network: nodes whose sum represents the number of features in each layer.\n\nQuestion: How do BERT's results on different NLP tasks compare to those of the best models that came before it?\nAnswer:  BERT's performance on multiple tasks compares to that of a Best Answer model, offering performance advantages on a wide range of tasks.\n\nQuestion: How to decide if the data is linearly separable or not in the case of data with dimensions more than 3?\nAnswer:  Linear separability or linearity depends on the problem and data characteristics of the dataset.\n\nQuestion: What is the concept of \"discount factor\" in Reinforcement Learning?\nAnswer:  The idea behind \"discount factor\" is to help in learning reinforcement by penalizing the hidden values of a hidden feature, while retaining the reward function of the hidden feature.\n\nQuestion:  in simple terms, how is this feedback different from backpropagation?\nAnswer:  In backpropagation, the feedback can be set explicitly through a sequence of actions within an object, such as selecting a specific shape or placing a label on the relevant feature.\n\nQuestion: Importance of data preprocessing in machine learning?\nAnswer:  Data preprocessing is crucial to improving model performance, efficiency and reducing misspellings, particularly in low-dimensional features.\n\nQuestion: What is a Perceptron?\nAnswer:  A Perceptron is a type of information processing system in robotics that consists of several layers of layers of interconnected gates, sensors, and other components.\n\nQuestion: Explain the concept of an \"exploration strategy\" in Reinforcement Learning.\nAnswer:  In Reinforcement Learning, exploration strategies include tasks like solving complex problems in memory, capturing rewards, and expanding the network's reward network to include diverse perspectives and objectives.\n\nQuestion: How does Stable Diffusion work?\nAnswer:  Stable Diffusion uses a diffusion process called compression between pixel layers to achieve a more stable image by utilizing diffusion between different regions of the input image.\n\nQuestion: What are some of the main ways to use Stable Diffusion?\nAnswer:  Stable Diffusion allows us to directly compare the weights of a Convolutional Neural Network (CNN) to the weights of real-world images, enabling diverse visualization applications.\n\nQuestion: Different Types of Machine Learning algorithms?\nAnswer:  A basic machine learning algorithm (MLA) is known as a model-action model (MSA) or autoencoder (AIM).\n\nQuestion: Which distance measure can best optimize within-cluster homogeneity & across-cluster heterogeneity?\nAnswer:  Distance measuring between clusters is the best proxy for the overall homogeneity of a dataset, but it may require experimentation.\n\nQuestion: Is Stride is always 1 or it can be 1 ,2 or any other number?\nAnswer:  Stride is always 1,2 or any other number or combination of those numbers.\n\nQuestion: What is a false positive?\nAnswer:  A false positive represents a lack of knowledge or place in the data set where a person can't possibly have knowledge from.\n\nQuestion: Can we combine speech and video to understand the emotional quotient?\nAnswer:  In speech, the emotional quotient is information about the meaning or significance of the words used, indicative of emotional content.\n\nQuestion: Why would you use the Kernel Trick?\nAnswer:  The Kernel Trick assumes that any transformation in the kernel (a hyperplane) always occurs on a fixed spot, which means that the loss function becomes linear if we adjust the kernel.\n\nQuestion: Can the number of clusters change during the iteration?\nAnswer:  The number of clusters changes during the training and iterative stages of a data segmentation analysis.\n\nQuestion: Advantages and disadvantages of decision trees?\nAnswer:  Decision trees can be difficult to understand or visualize, affecting their accuracy and complexity.\n\nQuestion: Are there ethical considerations regarding AI-ML avatars?\nAnswer:  No, ethical considerations regarding AI-ML avatars include ethical concerns, privacy, and the role of the AI in the design of the models.\n\nQuestion: What is the difference between Model-Free and Model-Based Reinforcement Learning?\nAnswer:  Model-free models are supervised learning models where predictions are made based on the input data.\n\nQuestion: How does NLP process when one uses more than one language to express?\nAnswer:  NLP processes both single and multiple languages in order to define, categorize, and categorize information.\n\nQuestion: Listing popular distribution curves and their algorithmic scenarios?\nAnswer:  Supervised learning, Reinforcement Learning, Regression, & Cosine Trick commonly include popular model names like Gaussian Entropy, Linear Regression, and Tangent Regression.\n\nQuestion: What are some challenges in deploying machine learning models to production?\nAnswer:  Deployment challenges include training models to handle unusual data, handling outliers, and challenging predictive models to accurately predict future outcomes.\n\nQuestion: Do we have to keep updating the model periodically, based on new data?\nAnswer:  Data updates are usually carried out periodically if the model is getting better, since improvements occur when new data becomes available.\n\nQuestion: What are different types of Quantization that is used to save the storage space of many parameters of the network by compressing the weights.\nAnswer:  Different types of Quantization are commonly used to extract parameters from a big data setQuestion2 : What are some types of DVD that can be used to compress a large dataset for.\n\nQuestion: What is the key idea behind the paper \"Knowledge reasoning with semantic data for real-time data processing in smart factory\" by Wang et al.?\nAnswer:  Understanding the concept of knowledge reasoning with semantic data for real-time data processing in smart machine learning frameworks is an important concept that has gained growing attention due to its potential applications.\n\nQuestion: What are the different types of deep neural networks?\nAnswer:  Deep neural networks are typically constructed using generative models, or classifiers, to construct neural networks with diverse classes of features, resulting in a robust and stable architecture that excels.\n\nQuestion: How does squeeze work?\nAnswer:  By squeezing an input vector, the input vector is compressed onto a new vector of the same size as the input vector.\n\nQuestion: What is GPU?\nAnswer:  GPU is a type of machine learning pipeline that supports high-dimensional data, efficiently performs calculations, and is used for parallel processing on GPUs compared to traditional ML systems.\n\nQuestion: What is the purpose of positional encoding in the Transformer architecture?\nAnswer:  This encoding helps interpret the context of a sequence of input signals.\n\nQuestion: Name some pretrained architectures used for image classification\nAnswer:  Robust image classification is often used for image classification tasks in Machine Learning, particularly when the dataset is large.\n\nQuestion: What is the goal of reinforcement learning?\nAnswer:  It is to improve model performance and increase the overall accuracy of training algorithms.\n\nQuestion: What is data augmentation? Can you give some examples?\n\nAnswer:  Data augmentation involves augmentation techniques like autoencoders, vectors, or Gaussian kernels.\n\nQuestion: What are the three processing steps involved in deep learning workflow to solve real-world problems?\nAnswer:  Sequential processing, preprocessing, finalization, and convergence tasks enable efficient model training, while parallel processing and batch processing handle significant batch sizes.\n\nQuestion: Briefly explain what the BERT model is.\nAnswer:  The BERT model is a self-attention mechanism for training and testing predictions based on self-attention mechanisms.\n\nQuestion: can a Convolution filter be a encoder\nAnswer:  It can be a Convolution filter for both convolutional and multi-head language modeling, and it can be used for both linear and quadratic tasks.\n\nQuestion: Does having more Support Vectors impact the running time of the SVM algorithm?\nAnswer:  The more support structures in the SVM algorithm, the more powerful the model will be.\n\nQuestion: How is \"Top-5 Error %\" defined?\nAnswer:  The top-5 error percentage refers to the  In general, the error rate at which a prediction's accuracy is often incorrect, is commonly known as \"Top-5 Error.\n\nQuestion: What are the automated methods for Feature Engineering?\nAnswer:  This article explains the automated methods for feature engineering.\n\nQuestion: How can cloud APIs facilitate collaborative machine learning projects?\nAnswer:  Cloud APIs can be implemented for a collaborative project through machine learning techniques, leveraging the cloud.\n\nQuestion: What is deep learning?\nAnswer:  Deep learning represents the match of two different domains with various applications.\n\nQuestion: Handling missing or corrupted values in a dataset?\nAnswer:  Missing values in a dataset may occur due to the methods used or error codes used to extract them during the extraction process.\n\nQuestion: Can you give an example of a hybrid deep learning model that combines both generative and discriminative components?\nAnswer:  Clarence Aronson has developed a hybrid deep learning model for both generative and discriminative tasks in his field, creating a hybrid model capable of handling both generative and discrim.\n\nQuestion: Is it possible to use KNN for image processing?\nAnswer:  Yes, KNN is a powerful convolutional neural network, designed specifically for image processing tasks.\n\nQuestion: What is a voting model?\nAnswer:  A voting model is a type of machine greenscale that is used to identify an optimal vote.\n\nQuestion: Different types of data preprocessing techniques?\nAnswer:  Techniques like Gaussian occlusion/supervised learning, gradient boosting, dimensionality reduction, hyperparameter tuning, and other methods contribute to the development of new techniques in.\n\nQuestion: What is a diffusion model?\nAnswer:  A diffusion model is a neural network that is used to model the  input sequence in a series to find the optimal output.\n\nQuestion: What is model pruning, and how does it help in deploying models on resource-constrained devices?\nAnswer:  Pruning an AI model involves pruning the entire model array, which it then computes through a series of pruning iterations.\n\nQuestion: Why Do We Need the BLEU Score?\nAnswer:  The BLEU Score measures the proportion of variance in a dataset.\n\nQuestion: If we avoid padding, does it mean loss of information?\nAnswer:  Punctuation, or the removal of all single character or single line characters at a time, involves handling the input sequence in one word at a time.\n\nQuestion: batch vs SGD\nAnswer:  Batch processing typically scores better on image quality, especially considering how much time it takes to process each image.\n\nQuestion: Clustering in supervising and classifying in Unsupervised learning\nAnswer:  Unsupervised learning combines supervised learning, unsupervised learning, and regularization because the model learns from input features with respect to their classifiers.\n\nQuestion: Provide an example of a real-world application of computer vision in healthcare.\nAnswer:  Imagery of disease information and the functioning of systems is often used to illustrate healthcare systems.\n\nQuestion: Differentiate between Linear Regression and Support Vector Machines (SVMs).\nAnswer:  Linear Regression is a linear regression-based approach that maximizes the variance of the results for a regression line.\n\nQuestion: What are some common types of Ensemble Methods?\nAnswer:  Ensemble Methods have multiple methods involved in constructing a single array of representations.\n\nQuestion: Do we have to use visualization techniques such as t-SNE?\nAnswer:  T-SNE, which offers deep learning-based techniques for image manipulation, has gone through extensive iterations, especially when dealing with images for classification and visualization reasons.\n\nQuestion: What is Deep Learning (DL)?\\n\nAnswer:  Deep Learning (DL) is a set of deep learning techniques, most commonly used in machine learning applications.\n\nQuestion: Do we always take +ve slope? I f so why we are taking only +ve slope\nAnswer:  In linear regression, if the slope of the regression line is greater than 0 (i.\n\nQuestion: What is semi-supervised learning?\nAnswer:  Mentioned in the paper by Kulkarni et al.\n\nQuestion: when every problem can be solved by neural networks. Then what is the significance of learning other machine learning algos.?\nAnswer:  The importance of using machine learning for problem solving lies in enabling learning beyond human knowledge.\n\nQuestion: How does a GRU enable it to capture dependencies from large sequences of data?\nAnswer:  One GRU learns over time from the previous input sequence, collecting information about the  dependencies of the previous input sequence and its dependencies.\n\nQuestion: How can we evaluate the predictions Object Detection model\nAnswer:  To evaluate the predictions of a model, it must first verify that observations given the predictions match.\n\nQuestion: What is F1 score? How would you use it?\nAnswer:  F1 scores are score thresholds used to determine the average score in a given machine learning context.\n\nQuestion: Briefly explain the underlying architecture that serves as the foundation for recent language models like BERT, GPT, and T5.\nAnswer:  BERT stands for Bilingual Programming Standard, an interdependent framework that integrates standard programming languages into a hypertextual model.\n\nQuestion: What is MNIST\nAnswer:  MNIST is a simple linear regression equation, used to determine the minimum and maximum likelihood of predicting standard deviation.\n\nQuestion: Briefly discuss the text corpora that were used to pretrain BERT.\nAnswer:  BERT was pretrained using a vocabulary analysis toolkit called Riemann.\n\nQuestion: Which BERT process is more computationally expensive: pretraining or fine tuning?\nAnswer:  BERT produces synthetic weights with reduced learning cost resulting in a more stable training environment.\n\nQuestion: why do we need to understand the features extracted by CNN? can't we just feed it into Random Forest and let the machine do its job? Why cant we do backpropagation including Random Forest?\nAnswer:  A backpropagation feature can be extracted from CNN using backpropagation methods like ensemble regression, regression-wise, or convergence rule tuning, depending on how the feature.\n\nQuestion: do search engines also use web scraping?\nAnswer:  Search engines use web scraping tools to scrape web pages for content.\n\nQuestion: is RNN doing backpropagation with the help of human?\nAnswer:  Backpropagation by machine interprets the image as representing a continuous line.\n\nQuestion: What are the advantages of using actor-critic methods in Reinforcement Learning?\nAnswer:  Ans.\n\nQuestion: Can Machine Learning models handle non-numeric data?\nAnswer:  Yes, Machine Learning models can handle non-numeric data efficiently; however, it is recommended that numerical data be considered separate from numeric data to preventnlity in data interpretation.\n\nQuestion: How does Scikit-Learn facilitate model evaluation and validation?\nAnswer:  Scikit-Learn offers tools such as pre-trained models, pre-trained models in machine learning applications, and self-learning tutorials for deploying and tuning pre-trained models.\n\nQuestion: Provide an example of a constraint in machine learning for a medical diagnosis application.\nAnswer:  If a condition is associated with a classification problem, then the model may use non-classical methods to classify, with increased specificity when handling such situations.\n\nQuestion: How does Bagging differ from Boosting in Ensemble Methods?\nAnswer:  While Bagging does not automatically convert the class from left to right, it does ensure that the transformers that minimize the class hierarchy are fully connected to the actual class during the.\n\nQuestion: in fully connected weight sharing is possible\nAnswer:  In fully connected weights sharing, the underlying assumption for a decision is that the shared weights match the weights assigned by the connected network.\n\nQuestion: What is an RNN (recurrent neural network)?\nAnswer:  An RNN is a recurrent neural network comprising a set of nodes, each node being connected to other nodes in the network by translating the input from one node to another in a.\n\nQuestion: What are stop words? \n\nAnswer:  stop words are words that are used to stop a word from repeatedly occurring in a sentence.\n\nQuestion: Linear regression is a method of finding the relationship between which variables?\nAnswer:  Linear regression finds relationships between variables that can be found in a dataset only by considering the most important ones with a fixed-output distribution.\n\nQuestion: GD is the only way for backpropagationor are there any variants that can replace GD for NN?\nAnswer:  The only alternative to GD is to use either the Transformer (GD-1) or Neuromodal (GD-2) libraries.\n\nQuestion: Explaining how SVM deals with self-learning?\nAnswer:  Self-learning involves removing unnecessary dependencies and learning new ones from data before and during training; it helps automate testing and validation.\n\nQuestion: Discussing kernels in SVM, their popular types, and application scenarios?\nAnswer:  NNs are general-purpose kernels used to represent the kernel of a data-vocabulary space as distinct from the kernel of the representation space.\n\nQuestion: How Biological neurons are similar to the Artificial neural network\nAnswer:  Autoencoders (AEs) are neurons with different functions and dependencies, whereas Spatial Autoencoders (SAEs) have distinct functions and dependencies.\n\nQuestion: How are POS Tags learned?\nAnswer:  POS Tags are learned through supervised learning, where a classifier learns from experience learned during training on a large dataset to identify the most commonly used language pronunciations in other languages.\n\nQuestion: when we convolve how do the weights get assigned in pytorch or keras\nAnswer:  In Keras, weights are applied as a parameter to the convolutional layers of convolutional layers to determine the probability of getting a certain weight.\n\nQuestion: Explain the different types of activation functions.\nAnswer:  Activation functions (lambda, square root, cosine polynomial, etc.\n\nQuestion: What is the role of a reward function in Reinforcement Learning?\nAnswer:  A reward function (BERP) is a mathematical function that determines the probability of obtaining new values by increasing the reward function.\n\nQuestion: how do we know what functions are there inside (which we are differentiating) ?\nAnswer:  Functions within a class like Recursive Regression are labeled with three underscores.\n\nQuestion: How does Scikit-Learn simplify the machine learning process?\nAnswer:  Scikit-Learn introduces a set of internal APIs for creating, manipulating, and managing machine learning models.\n\nQuestion: Explain the trade-off between exploration and exploitation in Reinforcement Learning.\nAnswer:  Exploration involves exploring new features and potentially surpassing the capabilities of the available data.\n\nQuestion: What is a continuous deep belief network (DBN)?\nAnswer:  A continuous deep belief network is a type of machine learning model and consists of interconnected neural networks that exhibit varying degrees of consistency and precision in task execution.\n\nQuestion: Can RGBa Images be considered as a 4D array?\nAnswer:  The RGBa image format is referred to as a 4D array.\n\nQuestion: What is the CART algorithm ?\nAnswer:  The technique of calculating the predicted output through the use of convolutional layers (CNNs) to model specific tasks in image classification is utilized by the CART algorithm to predict.\n\nQuestion: Is this Kernel transformation in SVM using Lagrange multipliers?\nAnswer:  No, we used Bayes' L1-means approximation.\n\nQuestion: What is the main idea of the paper \"Supervised Determined Source Separation with Multichannel Variational Autoencoder\" by Kameoka et al.?\nAnswer:  The paper introduces an approach to learn the source separation of source data through autoencoders, leveraging ensemble learning.\n\nQuestion: For every epoch, do we start with taking random weights? Or do we take weights from the previous epoch?\nAnswer:  In Machine Learning, starting with random weights reduces the training time by reducing linearity.\n\nQuestion: For every epoch, do we start with taking random weights ? Or do we take weights from previous epoch ?\nAnswer:  Random weights can be added, removed, or even repeated by preprocessing in parallel.\n\nQuestion: Is it possible to return multiple types of response from one endpoint using FastAPI?\nAnswer:  In FastAPI, the return type is a list of unique sequences for each type of response, with varying weights.\n\nQuestion: What is the main difference between Decision Trees and Random Forests?\nAnswer:  Decision Trees are designed for categorical outcomes; Random Forests are used for categorical outcomes; these trees are adapted for different types of regression.\n\nQuestion: Whats the difference between probability and likelihood?\nAnswer:  A probability probability distribution can lead to an increase in accurate predictions, especially in situations where accuracy is low.\n\nQuestion: What technologies support the development of AI-ML avatars?\nAnswer:  AI-ML avatars in the real world provide unique capabilities.\n\nQuestion: What's the main objective of this consonant classification?\nAnswer:  The main objective of the consonant classification is to find the minimum value between consonant clusters, and determine the maximum value between consonant clusters for the consonant clusters.\n\nQuestion: Difference between multi-class and multi-label classification problems.\nAnswer:  Multi-class classification problems have advantages over single-class classification problems because they use two classes of data, unlike multi-class classification, which has multiple classes.\n\nQuestion: Explain learning rate in the context of neural network models. What happens if the learning rate is too high or too low?\nAnswer:  In neural networks, the learning rate is the rate at which the network learns new information.\n\nQuestion: What is the main benefit of using a Self-Organizing Map (SOM)?\nAnswer:  The main benefit of using a Self-Organizing Maps (SOM) is that they help researchers locate and capture relationships within datasets, enabling them to more effectively assess and understand.\n\nQuestion: Why do we use a Pooling Layer in a CNN\nAnswer:  In a CNN, every node within a pooling layer is considered a random variable and can only be used as a random variable by itself.\n\nQuestion: What is the key idea behind K-sparse autoencoders, as proposed by Makhzani and Frey?\nAnswer:  The key idea of K-sparse autoencoders is to encode a pre-trained image as an input, allowing the model to incorporate diverse input data without compromising the.\n\nQuestion: Identifying the \"lazy learner\" machine learning algorithm?\nAnswer:  The \"lazy learner\" machine learning algorithm is defined in part by the hyperparameter learning algorithm.\n\nQuestion: How is NMT trained? Do we use pairs of sentences with same meaning across many languages?\nAnswer:  NMT employs an ensemble approach by rotating words at a fixed rate to capture context-sensitive patterns.\n\nQuestion: What is dense representation?\nAnswer:  Diffusion density is the measure of the number of items in a stack (or layer).\n\nQuestion: What is the purpose of using generative modeling in deep learning?\nAnswer:  Generative modeling helps in understanding complex patterns within neural networks (NE).\n\nQuestion: What is the name of the deep learning library developed by Facebook?\nAnswer:  Facebook is known for its deep learning library, called Laplace.\n\nQuestion: In what industries are AI-ML avatars widely adopted?\nAnswer:  Autonomous cars, health care, finance, and pharmaceuticals are some examples of businesses that are popularized by AI-ML avatars.\n\nQuestion: How do we choose different Kernel functions?\nAnswer:  In the context of kernel functions, the choice needs to be based on features, performance concerns, and specific criteria, not on the kernel's specific nature.\n\nQuestion: How does NLP process when one uses more than one language to express ?\nAnswer:  NLP processes in one language only for the input to be parsed.\n\nQuestion: What is the main idea behind the paper \"Learning to represent spatial transformations with factored higher-order Boltzmann machines\" by Memisevic and Hinton?\nAnswer:  The main idea behind the paper was to train a hyper-parameter-free model (parameters) for spatial transformations by multiplying the weights of the hyperparameter-free.\n\nQuestion: what is clamp\nAnswer:  It's a technique that separates the output from encoder.\n\nQuestion: We have also seen the prediction for Time Series can be done by ARIMA and as well RNN  which is a better model ?\nAnswer:  ARIMA (Automated Image Generative Adversarial) and ASNN combine the ability to capture temporal and spatial information and enables the performance of deep learning supervised tasks with.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"kaggle kernels pull tany14/qa-gpt-own-data","metadata":{},"execution_count":null,"outputs":[]}]}